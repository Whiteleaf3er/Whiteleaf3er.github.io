<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>图片测试</title>
    <url>/2020/03/18/%E5%9B%BE%E7%89%87%E6%B5%8B%E8%AF%95/</url>
    <content><![CDATA[<p><img src="/.com//%E5%9B%BE%E7%89%87%E6%B5%8B%E8%AF%95%5Cimage-20200317203456905.png" alt="image-20200317203456905"></p>
]]></content>
  </entry>
  <entry>
    <title>语义分割综述</title>
    <url>/2020/03/17/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<h1 id="什么是语义分割"><a href="#什么是语义分割" class="headerlink" title="什么是语义分割"></a>什么是语义分割</h1><p>计算机视觉的相关任务从图像识别分类到目标检测到语义分割，任务量的难度逐步加大，图像识别仅仅需要预测出一张图片是哪一个类别，目标检测需要将图片中包含的各个类都用方框框起来，对每个框进行预测，而语义分割是对每一个像素点进行预测，通常又被称为密集预测。</p>
<p><img src="/.com//%5C%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BB%BC%E8%BF%B0%5Cimage-20200317203550548.png" alt="image-20200317203550548"></p>
<a id="more"></a>

<h1 id="语义分割模型"><a href="#语义分割模型" class="headerlink" title="语义分割模型"></a>语义分割模型</h1><p>通常图像分割模型是<strong>Encoder-Decoder</strong>结构。Encoder部分通过<strong>下采样</strong>降低输入的空间分辨率，从而生成一个低分辨率的特征映射（计算高效且能够有效区分不同类别）；Decoder则对这些特征描述进行<strong>上采样</strong>，将其恢复成全分辨率的分割图。</p>
<p><img src="/.com//%5C%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BB%BC%E8%BF%B0%5Cimage-20200317203456905.png" alt="image-20200317203456905"></p>
<h2 id="Segnet模型"><a href="#Segnet模型" class="headerlink" title="Segnet模型"></a>Segnet模型</h2><h4 id="简述Segnet"><a href="#简述Segnet" class="headerlink" title="简述Segnet"></a>简述Segnet</h4><p>segnet属于基础的语义分割模型，结构类似于上图，编码部分可以采用不同的网络结构进行下采样降低分辨率并提取特征，比如VGG或Mobilenet，VGG再经典不过，都比较熟悉，3*3的卷积和池化堆叠，这里简述一下Mobilenet的网络结构</p>
<h4 id="Encoder模块——Mobilenet网络结构"><a href="#Encoder模块——Mobilenet网络结构" class="headerlink" title="Encoder模块——Mobilenet网络结构"></a>Encoder模块——Mobilenet网络结构</h4><p>MobileNet模型是Google针对手机等嵌入式设备提出的一种轻量级的深层神经网络，其使用的核心思想便是<strong>depthwise separable convolution</strong>。</p>
<p>对于一个卷积过程而言：</p>
<p>正常的卷积操作：假设有一个3×3大小的卷积层，其输入通道为16、输出通道为32。我是这样理解的，WxHx16的图像通过3x3x16的卷积核进行卷积，卷积过程中每个3x3x1遍历对应的WxHx1，如果是SAME的形式输出分辨率不变则是，WxHx1，而3x3x16就会得到16个WxHx1即WxHx16，WxH中各个像素点相加（16个相叠加），则得到了WxHx1，但是这里不仅是3x3x16，还要注意输出通道数，也就是3x3x16x32，32个3x3x16的卷积核会遍历输入图像中的16个输入通道，所以输出是WxHx32，所需参数为16×32×3×3=4608个。</p>
<p><img src="/.com//%5C%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BB%BC%E8%BF%B0%5Cimage-20200317205448920.png" alt="image-20200317205448920"></p>
<p>应用深度可分离卷积：第一步为<strong>Depthwise conv</strong>用16个3×3大小的卷积核<strong>分别遍历</strong>16通道的数据，得到了16个特征图谱。也就是第i个3x3的卷积核负责遍历第i个输入通道得到WxH的特征图。接着第二步为<strong>Pointwise conv</strong>，用32个1×1大小的卷积核遍历这16个特征图，其实第二步也就是正常的卷积操作。所需参数为16×3×3+16×32×1×1=656个。</p>
<p><img src="/.com//%5C%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BB%BC%E8%BF%B0%5Cimage-20200317205417730.png" alt="image-20200317205417730"></p>
<p>重点在于理解<strong>Depthwise conv</strong>中的每个卷积核负责一个输入通道输出一个通道，而不是正常卷积操作中的每个卷积核负责一个通道，但输出的是1/32个输出通道（还有其他卷积核的结果加起来，才是一个输出通道）</p>
<p>知道了核心模块其余就很简单了，各种卷积的堆叠</p>
<p><img src="https://img-blog.csdnimg.cn/20191030153845940.png#pic_center" alt="在这里插入图片描述"></p>
<h4 id="Encoder代码（Mobilenet结构）"><a href="#Encoder代码（Mobilenet结构）" class="headerlink" title="Encoder代码（Mobilenet结构）"></a>Encoder代码（Mobilenet结构）</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> keras.backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"></span><br><span class="line">IMAGE_ORDERING = <span class="string">'channels_last'</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu6</span><span class="params">(x)</span>:</span></span><br><span class="line">	<span class="keyword">return</span> K.relu(x, max_value=<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_conv_block</span><span class="params">(inputs, filters, alpha, kernel=<span class="params">(<span class="number">3</span>, <span class="number">3</span>)</span>, strides=<span class="params">(<span class="number">1</span>, <span class="number">1</span>)</span>)</span>:</span></span><br><span class="line"></span><br><span class="line">	channel_axis = <span class="number">1</span> <span class="keyword">if</span> IMAGE_ORDERING == <span class="string">'channels_first'</span> <span class="keyword">else</span> <span class="number">-1</span></span><br><span class="line">	filters = int(filters * alpha)</span><br><span class="line">	x = ZeroPadding2D(padding=(<span class="number">1</span>, <span class="number">1</span>), name=<span class="string">'conv1_pad'</span>, data_format=IMAGE_ORDERING  )(inputs)</span><br><span class="line">	x = Conv2D(filters, kernel , data_format=IMAGE_ORDERING  ,</span><br><span class="line">										padding=<span class="string">'valid'</span>,</span><br><span class="line">										use_bias=<span class="literal">False</span>,</span><br><span class="line">										strides=strides,</span><br><span class="line">										name=<span class="string">'conv1'</span>)(x)</span><br><span class="line">	x = BatchNormalization(axis=channel_axis, name=<span class="string">'conv1_bn'</span>)(x)</span><br><span class="line">	<span class="keyword">return</span> Activation(relu6, name=<span class="string">'conv1_relu'</span>)(x)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_depthwise_conv_block</span><span class="params">(inputs, pointwise_conv_filters, alpha,</span></span></span><br><span class="line"><span class="function"><span class="params">													depth_multiplier=<span class="number">1</span>, strides=<span class="params">(<span class="number">1</span>, <span class="number">1</span>)</span>, block_id=<span class="number">1</span>)</span>:</span></span><br><span class="line"></span><br><span class="line">	channel_axis = <span class="number">1</span> <span class="keyword">if</span> IMAGE_ORDERING == <span class="string">'channels_first'</span> <span class="keyword">else</span> <span class="number">-1</span></span><br><span class="line">	pointwise_conv_filters = int(pointwise_conv_filters * alpha)</span><br><span class="line"></span><br><span class="line">	x = ZeroPadding2D((<span class="number">1</span>, <span class="number">1</span>) , data_format=IMAGE_ORDERING , name=<span class="string">'conv_pad_%d'</span> % block_id)(inputs)</span><br><span class="line">	x = DepthwiseConv2D((<span class="number">3</span>, <span class="number">3</span>) , data_format=IMAGE_ORDERING ,</span><br><span class="line">														 padding=<span class="string">'valid'</span>,</span><br><span class="line">														 depth_multiplier=depth_multiplier,</span><br><span class="line">														 strides=strides,</span><br><span class="line">														 use_bias=<span class="literal">False</span>,</span><br><span class="line">														 name=<span class="string">'conv_dw_%d'</span> % block_id)(x)</span><br><span class="line">	x = BatchNormalization(</span><br><span class="line">			axis=channel_axis, name=<span class="string">'conv_dw_%d_bn'</span> % block_id)(x)</span><br><span class="line">	x = Activation(relu6, name=<span class="string">'conv_dw_%d_relu'</span> % block_id)(x)</span><br><span class="line"></span><br><span class="line">	x = Conv2D(pointwise_conv_filters, (<span class="number">1</span>, <span class="number">1</span>), data_format=IMAGE_ORDERING ,</span><br><span class="line">										padding=<span class="string">'same'</span>,</span><br><span class="line">										use_bias=<span class="literal">False</span>,</span><br><span class="line">										strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">										name=<span class="string">'conv_pw_%d'</span> % block_id)(x)</span><br><span class="line">	x = BatchNormalization(axis=channel_axis,</span><br><span class="line">																name=<span class="string">'conv_pw_%d_bn'</span> % block_id)(x)</span><br><span class="line">	<span class="keyword">return</span> Activation(relu6, name=<span class="string">'conv_pw_%d_relu'</span> % block_id)(x)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_mobilenet_encoder</span><span class="params">( input_height=<span class="number">224</span> ,  input_width=<span class="number">224</span> , pretrained=<span class="string">'imagenet'</span> )</span>:</span></span><br><span class="line"></span><br><span class="line">	alpha=<span class="number">1.0</span></span><br><span class="line">	depth_multiplier=<span class="number">1</span></span><br><span class="line">	dropout=<span class="number">1e-3</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	img_input = Input(shape=(input_height,input_width , <span class="number">3</span> ))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	x = _conv_block(img_input, <span class="number">32</span>, alpha, strides=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">	x = _depthwise_conv_block(x, <span class="number">64</span>, alpha, depth_multiplier, block_id=<span class="number">1</span>) </span><br><span class="line">	f1 = x</span><br><span class="line"></span><br><span class="line">	x = _depthwise_conv_block(x, <span class="number">128</span>, alpha, depth_multiplier,</span><br><span class="line">														strides=(<span class="number">2</span>, <span class="number">2</span>), block_id=<span class="number">2</span>)  </span><br><span class="line">	x = _depthwise_conv_block(x, <span class="number">128</span>, alpha, depth_multiplier, block_id=<span class="number">3</span>) </span><br><span class="line">	f2 = x</span><br><span class="line"></span><br><span class="line">	x = _depthwise_conv_block(x, <span class="number">256</span>, alpha, depth_multiplier,</span><br><span class="line">														strides=(<span class="number">2</span>, <span class="number">2</span>), block_id=<span class="number">4</span>)  </span><br><span class="line">	x = _depthwise_conv_block(x, <span class="number">256</span>, alpha, depth_multiplier, block_id=<span class="number">5</span>) </span><br><span class="line">	f3 = x</span><br><span class="line"></span><br><span class="line">	x = _depthwise_conv_block(x, <span class="number">512</span>, alpha, depth_multiplier,</span><br><span class="line">														strides=(<span class="number">2</span>, <span class="number">2</span>), block_id=<span class="number">6</span>) </span><br><span class="line">	x = _depthwise_conv_block(x, <span class="number">512</span>, alpha, depth_multiplier, block_id=<span class="number">7</span>) </span><br><span class="line">	x = _depthwise_conv_block(x, <span class="number">512</span>, alpha, depth_multiplier, block_id=<span class="number">8</span>) </span><br><span class="line">	x = _depthwise_conv_block(x, <span class="number">512</span>, alpha, depth_multiplier, block_id=<span class="number">9</span>) </span><br><span class="line">	x = _depthwise_conv_block(x, <span class="number">512</span>, alpha, depth_multiplier, block_id=<span class="number">10</span>) </span><br><span class="line">	x = _depthwise_conv_block(x, <span class="number">512</span>, alpha, depth_multiplier, block_id=<span class="number">11</span>) </span><br><span class="line">	f4 = x </span><br><span class="line"></span><br><span class="line">	x = _depthwise_conv_block(x, <span class="number">1024</span>, alpha, depth_multiplier,</span><br><span class="line">														strides=(<span class="number">2</span>, <span class="number">2</span>), block_id=<span class="number">12</span>)  </span><br><span class="line">	x = _depthwise_conv_block(x, <span class="number">1024</span>, alpha, depth_multiplier, block_id=<span class="number">13</span>) </span><br><span class="line">	f5 = x </span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> img_input , [f1 , f2 , f3 , f4 , f5 ]</span><br></pre></td></tr></table></figure>

<p>由上代码发现返回了$ f_i $（i=12345），这个是什么呢？</p>
<p>可以发现每个 $ f_i $到$ f_{i+1} $之间都有一次strides = （2，2）的conv操作，也就每次图像的分辨率都缩小了一倍</p>
<p>例如f4的shape是N x H/16 x W/16 x 512</p>
<p>而这些$ f_i $有什么用了，进入<strong>decoder</strong>部分吧</p>
<h4 id="Decoder模块"><a href="#Decoder模块" class="headerlink" title="Decoder模块"></a>Decoder模块</h4><p>Decoder将图像<strong>分辨率进行恢复</strong>，把<strong>获得的特征</strong>重新映射到图中的每一个像素点，用于<strong>每一个像素点的分类</strong>。</p>
<p>所以这也是为什么要保存$ f_i $的原因了，因为需要把特征进行再利用</p>
<p>如何将分辨率恢复呢？重点在于上采样模块</p>
<p><img src="https://img-blog.csdnimg.cn/20181223184533975.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzc1ODEw,size_16,color_FFFFFF,t_70" alt="img"></p>
<p>具体的操作其实也就是逐行逐列一一复制添加</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> UpSampling2D</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">x=np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>,<span class="number">13</span>,<span class="number">14</span>,<span class="number">15</span>,<span class="number">16</span>])</span><br><span class="line">x=x.reshape(<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">1</span>)</span><br><span class="line">print(x)</span><br><span class="line">x=tf.convert_to_tensor(x)</span><br><span class="line">y=UpSampling2D(size=(<span class="number">2</span>,<span class="number">2</span>))(x)</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(y.eval())</span><br></pre></td></tr></table></figure>

<p>print(x):</p>
<p><img src="/.com//%5C%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BB%BC%E8%BF%B0%5Cimage-20200317212212721.png" alt="image-20200317212212721"></p>
<p>print(y.eval()):</p>
<p><img src="/.com//%5C%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BB%BC%E8%BF%B0%5Cimage-20200317212249458.png" alt="image-20200317212249458"></p>
<h4 id="Decoder代码"><a href="#Decoder代码" class="headerlink" title="Decoder代码"></a>Decoder代码</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> nets.mobilenet <span class="keyword">import</span> get_mobilenet_encoder</span><br><span class="line"></span><br><span class="line">IMAGE_ORDERING = <span class="string">'channels_last'</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">segnet_decoder</span><span class="params">(  f , n_classes , n_up=<span class="number">3</span> )</span>:</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">assert</span> n_up &gt;= <span class="number">2</span></span><br><span class="line"></span><br><span class="line">	o = f</span><br><span class="line">	o = ( ZeroPadding2D( (<span class="number">1</span>,<span class="number">1</span>) , data_format=IMAGE_ORDERING ))(o)</span><br><span class="line">	o = ( Conv2D(<span class="number">512</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'valid'</span>, data_format=IMAGE_ORDERING))(o)</span><br><span class="line">	o = ( BatchNormalization())(o)</span><br><span class="line">	<span class="comment"># 进行一次UpSampling2D，此时hw变为原来的1/8</span></span><br><span class="line">	<span class="comment"># 52,52,512</span></span><br><span class="line">	o = ( UpSampling2D( (<span class="number">2</span>,<span class="number">2</span>), data_format=IMAGE_ORDERING))(o)</span><br><span class="line">	o = ( ZeroPadding2D( (<span class="number">1</span>,<span class="number">1</span>), data_format=IMAGE_ORDERING))(o)</span><br><span class="line">	o = ( Conv2D( <span class="number">256</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'valid'</span>, data_format=IMAGE_ORDERING))(o)</span><br><span class="line">	o = ( BatchNormalization())(o)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 进行一次UpSampling2D，此时hw变为原来的1/4</span></span><br><span class="line">	<span class="comment"># 104,104,256</span></span><br><span class="line">	<span class="keyword">for</span> _ <span class="keyword">in</span> range(n_up<span class="number">-2</span>):</span><br><span class="line">		o = ( UpSampling2D((<span class="number">2</span>,<span class="number">2</span>)  , data_format=IMAGE_ORDERING ) )(o)</span><br><span class="line">		o = ( ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>) , data_format=IMAGE_ORDERING ))(o)</span><br><span class="line">		o = ( Conv2D( <span class="number">128</span> , (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'valid'</span> , data_format=IMAGE_ORDERING ))(o)</span><br><span class="line">		o = ( BatchNormalization())(o)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 进行一次UpSampling2D，此时hw变为原来的1/2</span></span><br><span class="line">	<span class="comment"># 208,208,128</span></span><br><span class="line">	o = ( UpSampling2D((<span class="number">2</span>,<span class="number">2</span>)  , data_format=IMAGE_ORDERING ))(o)</span><br><span class="line">	o = ( ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)  , data_format=IMAGE_ORDERING ))(o)</span><br><span class="line">	o = ( Conv2D( <span class="number">64</span> , (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'valid'</span>  , data_format=IMAGE_ORDERING ))(o)</span><br><span class="line">	o = ( BatchNormalization())(o)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 此时输出为h_input/2,w_input/2,nclasses</span></span><br><span class="line">	o =  Conv2D( n_classes , (<span class="number">3</span>, <span class="number">3</span>) , padding=<span class="string">'same'</span>, data_format=IMAGE_ORDERING )( o )</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">return</span> o </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_segnet</span><span class="params">( n_classes , encoder  ,  input_height=<span class="number">416</span>, input_width=<span class="number">608</span> , encoder_level=<span class="number">3</span>)</span>:</span></span><br><span class="line">	<span class="comment"># encoder通过主干网络</span></span><br><span class="line">	img_input , levels = encoder( input_height=input_height ,  input_width=input_width )</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 获取hw压缩四次后的结果</span></span><br><span class="line">	feat = levels[encoder_level]</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 将特征传入segnet网络</span></span><br><span class="line">	o = segnet_decoder(feat, n_classes, n_up=<span class="number">3</span> )</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 将结果进行reshape</span></span><br><span class="line">	o = Reshape((int(input_height/<span class="number">2</span>)*int(input_width/<span class="number">2</span>), <span class="number">-1</span>))(o)</span><br><span class="line">	o = Softmax()(o)</span><br><span class="line">	model = Model(img_input,o)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mobilenet_segnet</span><span class="params">( n_classes ,  input_height=<span class="number">224</span>, input_width=<span class="number">224</span> , encoder_level=<span class="number">3</span>)</span>:</span></span><br><span class="line"></span><br><span class="line">	model = _segnet( n_classes , get_mobilenet_encoder ,  input_height=input_height, input_width=input_width , encoder_level=encoder_level)</span><br><span class="line">	model.model_name = <span class="string">"mobilenet_segnet"</span></span><br><span class="line">	<span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>

<p>第49行：o = segnet_decoder(feat, n_classes, n_up=3 )</p>
<p>将分辨率降低4次后提取到的特征传入segnet网络进行上采样恢复，恢复后为H/2 x W/2 x nclasses，之后reshape为 HxW/4 x nclasses，再调用softmax函数进行分类</p>
<p>这里回想一下在一个图像5分类的工作中，某个batch_size = 1的batch，也就是一张图片在进入最后的softmax前shape为1 x 5，之后通过softmax得到5个类的概率值</p>
<p>而这里的segnet，<strong>1张图片通过softmax得到HxW/4 x nclasses的数据结构，表示的也就是H/2 x W/2这样一张图片，每个像素点都拥有对5个类别的预测概率值，也就实现了最初想要达到的对每个像素点进行预测</strong></p>
<h4 id="Segnet小结"><a href="#Segnet小结" class="headerlink" title="Segnet小结"></a>Segnet小结</h4><p>总的来说，Segnet是一个经典的语义分割网络结构，首先降低分辨率提取特征，再将某一次（第4次）提取到的特征进行上采样恢复分辨率，最后对大分辨率图像中每个像素点都进行类别预测</p>
<h2 id="Unet模型"><a href="#Unet模型" class="headerlink" title="Unet模型"></a>Unet模型</h2><h4 id="简述Unet"><a href="#简述Unet" class="headerlink" title="简述Unet"></a>简述Unet</h4><p>在进行segnet的详解的时候知道，其中<strong>只选了一个压缩了四次的特征层</strong>进行三次上采样得到最后的结果。<br>但是unet不一样，其<strong>用到了压缩了二、三、四次的特征层</strong>，最后输出图像分割的结果（可以选择是否需要压缩了一次的特征层）。也就是它利用了多个特征层，使得提取到的特征更加的丰富，为什么没有第一层呢？我猜想是因为第一层特征丰富度不够，所以直接放弃了2333</p>
<h4 id="Encoder模块"><a href="#Encoder模块" class="headerlink" title="Encoder模块"></a>Encoder模块</h4><p>与上述Segnet相同，采取Mobilenet来提取特征</p>
<h4 id="Decoder模块-1"><a href="#Decoder模块-1" class="headerlink" title="Decoder模块"></a>Decoder模块</h4><p>首先我们获得了f1，f2，f3，f4，f5，5个层次的特征，我们先看一下各自的shape</p>
<p>f1：208 x 208 x 64</p>
<p>f2：104 x 104 x 128</p>
<p>f3：52 x 52 x 256</p>
<p>f4：26 x 26 x 512</p>
<p>f5：13 x 13 x 1024</p>
<p>那么如何不同于Segnet仅利用到了f4，Unet如何利用f2-f4呢，其实主要就一个操作：</p>
<p>将fi上采样后达到与fi-1相同的分辨率，再进行concat拼接起来，再重复</p>
<p>我们来看一下代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> nets.mobilenet <span class="keyword">import</span> get_mobilenet_encoder</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">IMAGE_ORDERING = <span class="string">'channels_last'</span></span><br><span class="line">MERGE_AXIS = <span class="number">-1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_unet</span><span class="params">( n_classes , encoder , l1_skip_conn=True,  input_height=<span class="number">416</span>, input_width=<span class="number">608</span>  )</span>:</span></span><br><span class="line"></span><br><span class="line">	img_input , levels = encoder( input_height=input_height ,  input_width=input_width )</span><br><span class="line">	[f1 , f2 , f3 , f4 , f5 ] = levels </span><br><span class="line"></span><br><span class="line">	o = f4</span><br><span class="line">	<span class="comment"># 26,26,512</span></span><br><span class="line">	o = ( ZeroPadding2D( (<span class="number">1</span>,<span class="number">1</span>) , data_format=IMAGE_ORDERING ))(o)</span><br><span class="line">	o = ( Conv2D(<span class="number">512</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'valid'</span>, data_format=IMAGE_ORDERING))(o)</span><br><span class="line">	o = ( BatchNormalization())(o)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 52,52,512</span></span><br><span class="line">	o = ( UpSampling2D( (<span class="number">2</span>,<span class="number">2</span>), data_format=IMAGE_ORDERING))(o)</span><br><span class="line">	<span class="comment"># 52,52,768</span></span><br><span class="line">	o = ( concatenate([ o ,f3],axis=MERGE_AXIS )  )</span><br><span class="line">	o = ( ZeroPadding2D( (<span class="number">1</span>,<span class="number">1</span>), data_format=IMAGE_ORDERING))(o)</span><br><span class="line">	<span class="comment"># 52,52,256</span></span><br><span class="line">	o = ( Conv2D( <span class="number">256</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'valid'</span>, data_format=IMAGE_ORDERING))(o)</span><br><span class="line">	o = ( BatchNormalization())(o)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 104,104,256</span></span><br><span class="line">	o = ( UpSampling2D( (<span class="number">2</span>,<span class="number">2</span>), data_format=IMAGE_ORDERING))(o)</span><br><span class="line">	<span class="comment"># 104,104,384</span></span><br><span class="line">	o = ( concatenate([o,f2],axis=MERGE_AXIS ) )</span><br><span class="line">	o = ( ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>) , data_format=IMAGE_ORDERING ))(o)</span><br><span class="line">	<span class="comment"># 104,104,128</span></span><br><span class="line">	o = ( Conv2D( <span class="number">128</span> , (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'valid'</span> , data_format=IMAGE_ORDERING ) )(o)</span><br><span class="line">	o = ( BatchNormalization())(o)</span><br><span class="line">	<span class="comment"># 208,208,128</span></span><br><span class="line">	o = ( UpSampling2D( (<span class="number">2</span>,<span class="number">2</span>), data_format=IMAGE_ORDERING))(o)</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">if</span> l1_skip_conn:</span><br><span class="line">		o = ( concatenate([o,f1],axis=MERGE_AXIS ) )</span><br><span class="line"></span><br><span class="line">	o = ( ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)  , data_format=IMAGE_ORDERING ))(o)</span><br><span class="line">	o = ( Conv2D( <span class="number">64</span> , (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'valid'</span>  , data_format=IMAGE_ORDERING ))(o)</span><br><span class="line">	o = ( BatchNormalization())(o)</span><br><span class="line"></span><br><span class="line">	o =  Conv2D( n_classes , (<span class="number">3</span>, <span class="number">3</span>) , padding=<span class="string">'same'</span>, data_format=IMAGE_ORDERING )( o )</span><br><span class="line">	</span><br><span class="line">	<span class="comment"># 将结果进行reshape</span></span><br><span class="line">	o = Reshape((int(input_height/<span class="number">2</span>)*int(input_width/<span class="number">2</span>), <span class="number">-1</span>))(o)</span><br><span class="line">	o = Softmax()(o)</span><br><span class="line">	model = Model(img_input,o)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mobilenet_unet</span><span class="params">( n_classes ,  input_height=<span class="number">224</span>, input_width=<span class="number">224</span> , encoder_level=<span class="number">3</span>)</span>:</span></span><br><span class="line"></span><br><span class="line">	model =  _unet( n_classes , get_mobilenet_encoder ,  input_height=input_height, input_width=input_width  )</span><br><span class="line">	model.model_name = <span class="string">"mobilenet_unet"</span></span><br><span class="line">	<span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>

<p>我们来看看其中的15-24行做了什么：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">o = f4</span><br><span class="line"><span class="comment"># 26,26,512</span></span><br><span class="line">o = ( ZeroPadding2D( (<span class="number">1</span>,<span class="number">1</span>) , data_format=IMAGE_ORDERING ))(o)</span><br><span class="line">o = ( Conv2D(<span class="number">512</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">'valid'</span>, data_format=IMAGE_ORDERING))(o)</span><br><span class="line">o = ( BatchNormalization())(o)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 52,52,512</span></span><br><span class="line">o = ( UpSampling2D( (<span class="number">2</span>,<span class="number">2</span>), data_format=IMAGE_ORDERING))(o)</span><br><span class="line"><span class="comment"># 52,52,768</span></span><br><span class="line">o = ( concatenate([ o ,f3],axis=MERGE_AXIS )  )</span><br></pre></td></tr></table></figure>

<p>其实也就是对f4进行了一次<strong>上采样</strong>，26 x 26 x 512——52 x 52 x 512，此时分辨率与f3相同，再与f3进行<strong>拼接</strong>，f3为52 x 52 x 256，最后得到的shape为52 x 52 x 768</p>
<p>之后就是重复这个工作达到了<strong>利用多个特征层的目的</strong></p>
<h4 id="Unet小结"><a href="#Unet小结" class="headerlink" title="Unet小结"></a>Unet小结</h4><p>Unet相比于Segnet最大的改进之处即在于Decoder时<strong>利用了多个Encoder的特征层</strong>，核心在于将fi进行上采样后，与fi-1进行拼接，再重复工作</p>
<h2 id="Pspnet"><a href="#Pspnet" class="headerlink" title="Pspnet"></a>Pspnet</h2><h4 id="简述-Pspnet"><a href="#简述-Pspnet" class="headerlink" title="简述 Pspnet"></a>简述 Pspnet</h4><p>pspnet名字源于其主要采用了<strong>pspblock</strong></p>
<p>也就是psp模块。<br>psp模块的样式如下，其psp的核心重点是采用了步长不同，pool_size不同的平均池化层进行池化，然后将池化的结果重新resize到一个hw上后，再concatenate。<br>即：<br>红色：这是在每个特征map上执行全局平均池的最粗略层次，用于生成单个输出。<br>橙色：这是第二层，将特征map划分为2×2个子区域，然后对每个子区域进行平均池化。<br>蓝色：这是第三层，将特征 map划分为3×3个子区域，然后对每个子区域进行平均池化。<br>绿色：这是将特征map划分为6×6个子区域的最细层次，然后对每个子区域执行池化。<br><img src="/.com//%5C%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BB%BC%E8%BF%B0%5Cimage-20200317221518265.png" alt="image-20200317221518265"></p>
<p>比如下图，在psp_block中，input的shape为18 x 18 x 1024</p>
<p>首先是红色的，也就是全局均值池化，使用的pool_size和stride为18 x 18，输出为1x 1x 1024，再通过1 x 1的卷积核进行通道数调整，再通过resize_image为18 x 18的分辨率，输出为18 x 18 x 512</p>
<p>接着是橙色的，首先将18 x 18 x 1024 划分为4个区域，再对么区域进行均值池化，其代码实现也就是使用pool_size和stride为9 x 9，此时输出为2 x 2 x 1024，再调整通道数和分辨率，保证输出也为18 x 18 x 512</p>
<p>后两种类似</p>
<p><img src="/.com//%5C%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E7%BB%BC%E8%BF%B0%5Cimage-20200317221552692.png" alt="image-20200317221552692"></p>
<h4 id="Encoder模块-1"><a href="#Encoder模块-1" class="headerlink" title="Encoder模块"></a>Encoder模块</h4><p>类似，提取出多个特征层</p>
<h4 id="Decoder模块-2"><a href="#Decoder模块-2" class="headerlink" title="Decoder模块"></a>Decoder模块</h4><p>先上代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> nets.mobilenet <span class="keyword">import</span> get_mobilenet_encoder</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras_segmentation.models.model_utils <span class="keyword">import</span> get_segmentation_model</span><br><span class="line"></span><br><span class="line">IMAGE_ORDERING = <span class="string">'channels_last'</span></span><br><span class="line">MERGE_AXIS = <span class="number">-1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resize_image</span><span class="params">( inp ,  s , data_format )</span>:</span></span><br><span class="line">	<span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> Lambda( </span><br><span class="line">		<span class="keyword">lambda</span> x: tf.image.resize_images(</span><br><span class="line">			x , ( K.int_shape(x)[<span class="number">1</span>]*s[<span class="number">0</span>] ,K.int_shape(x)[<span class="number">2</span>]*s[<span class="number">1</span>] ))  </span><br><span class="line">		)( inp )</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pool_block</span><span class="params">( feats , pool_factor )</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> IMAGE_ORDERING == <span class="string">'channels_first'</span>:</span><br><span class="line">		h = K.int_shape( feats )[<span class="number">2</span>]</span><br><span class="line">		w = K.int_shape( feats )[<span class="number">3</span>]</span><br><span class="line">	<span class="keyword">elif</span> IMAGE_ORDERING == <span class="string">'channels_last'</span>:</span><br><span class="line">		h = K.int_shape( feats )[<span class="number">1</span>]</span><br><span class="line">		w = K.int_shape( feats )[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">	<span class="comment"># strides = [18,18],[9,9],[6,6],[3,3]</span></span><br><span class="line">	pool_size = strides = [int(np.round( float(h) /  pool_factor)), int(np.round(  float(w )/  pool_factor))]</span><br><span class="line"> </span><br><span class="line">	<span class="comment"># 进行不同程度的平均</span></span><br><span class="line">	x = AveragePooling2D(pool_size , data_format=IMAGE_ORDERING , strides=strides, padding=<span class="string">'same'</span>)( feats )</span><br><span class="line">	</span><br><span class="line">	<span class="comment"># 进行卷积</span></span><br><span class="line">	x = Conv2D(<span class="number">512</span>, (<span class="number">1</span> ,<span class="number">1</span> ), data_format=IMAGE_ORDERING , padding=<span class="string">'same'</span> , use_bias=<span class="literal">False</span> )( x )</span><br><span class="line">	x = BatchNormalization()(x)</span><br><span class="line">	x = Activation(<span class="string">'relu'</span> )(x)</span><br><span class="line"></span><br><span class="line">	x = resize_image( x , strides , data_format=IMAGE_ORDERING ) </span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_pspnet</span><span class="params">( n_classes , encoder ,  input_height=<span class="number">384</span>, input_width=<span class="number">576</span>  )</span>:</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">assert</span> input_height%<span class="number">192</span> == <span class="number">0</span></span><br><span class="line">	<span class="keyword">assert</span> input_width%<span class="number">192</span> == <span class="number">0</span></span><br><span class="line"></span><br><span class="line">	img_input , levels = encoder( input_height=input_height,input_width=input_width)</span><br><span class="line">	[f1 , f2 , f3 , f4 , f5 ] = levels </span><br><span class="line"></span><br><span class="line">	o = f5</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 对f5进行不同程度的池化</span></span><br><span class="line">	pool_factors = [ <span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">6</span>]</span><br><span class="line">	pool_outs = [o ]</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> p <span class="keyword">in</span> pool_factors:</span><br><span class="line">		pooled = pool_block(  o , p  )</span><br><span class="line">		pool_outs.append( pooled )</span><br><span class="line">	</span><br><span class="line">	<span class="comment"># 连接</span></span><br><span class="line">	o = Concatenate( axis=MERGE_AXIS)(pool_outs )</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 卷积</span></span><br><span class="line">	o = Conv2D(<span class="number">512</span>, (<span class="number">1</span>,<span class="number">1</span>), data_format=IMAGE_ORDERING, use_bias=<span class="literal">False</span> )(o)</span><br><span class="line">	o = BatchNormalization()(o)</span><br><span class="line">	o = Activation(<span class="string">'relu'</span> )(o)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 此时输出为[144,144,nclasses]</span></span><br><span class="line">	o = Conv2D( n_classes,(<span class="number">3</span>,<span class="number">3</span>),data_format=IMAGE_ORDERING, padding=<span class="string">'same'</span> )(o)</span><br><span class="line">	o = resize_image(o,(<span class="number">8</span>,<span class="number">8</span>),data_format=IMAGE_ORDERING)</span><br><span class="line">	o = Reshape((<span class="number">-1</span>,n_classes))(o)</span><br><span class="line">	o = Softmax()(o)</span><br><span class="line">	model = Model(img_input,o)</span><br><span class="line">	<span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mobilenet_pspnet</span><span class="params">( n_classes ,  input_height=<span class="number">224</span>, input_width=<span class="number">224</span> )</span>:</span></span><br><span class="line"></span><br><span class="line">	model =  _pspnet( n_classes , get_mobilenet_encoder ,  input_height=input_height, input_width=input_width  )</span><br><span class="line">	model.model_name = <span class="string">"mobilenet_pspnet"</span></span><br><span class="line">	<span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>

<p>需要注意的是<strong>Pspnet中输入图像为576 x 576，不同于Segnet和Unet的416 x 416</strong></p>
<p>所以提取出的f5为 18 x 18 x 1024，也就是上边所举的例子</p>
<ul>
<li>通过不同程度的池化，每一种池化输出为18 x 18 x512</li>
<li><strong>4种池化的结果加上自己本身f5进行拼接</strong>，输出为 18 x 18 x 2560</li>
<li>再通过卷积调整通道数为512，输出为 18 x 18 x 512</li>
<li>再通过卷积<strong>调整通道数</strong>为nclasses准备softmax计算概率</li>
<li>18 x 18太小 ，还需要<strong>恢复分辨率大小，使用resize调整分辨率大小</strong>，即8倍的宽高</li>
<li>之后就是经典的softmax预测工作</li>
</ul>
<h4 id="Pspnet小结"><a href="#Pspnet小结" class="headerlink" title="Pspnet小结"></a>Pspnet小结</h4><p>重点在于核心结构Psp_block，<strong>对Encoder后的特征层进行不同程度的池化，再拼接</strong>，再恢复调整分辨率与通道数ge</p>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2>]]></content>
      <categories>
        <category>滴滴实习-语义分割</category>
      </categories>
      <tags>
        <tag>语义分割</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo基本操作</title>
    <url>/2020/03/10/hexo%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<h2 id="Hexo添加menu中的分类-标签等"><a href="#Hexo添加menu中的分类-标签等" class="headerlink" title="Hexo添加menu中的分类/标签等"></a>Hexo添加menu中的分类/标签等</h2><p>博客最基本的需求就是对博文进行分类，初始化的Hexo只有首页和归档，如何进行添加呢？</p>
<ol>
<li>新建<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">hexo new<span class="built_in"> page </span>categories</span><br></pre></td></tr></table></figure>
这样会在/Hexo/source新建categories文件夹，里边包含index.md</li>
<li>处理index.md<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">title:</span> <span class="string">categories</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">2017</span><span class="number">-12</span><span class="number">-02</span> <span class="number">21</span><span class="string">:01:24</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">"categories"</span></span><br></pre></td></tr></table></figure>
在其中加入type字段即可</li>
</ol>
<a id="more"></a>

<ol start="3">
<li><p>处理主题配置文件</p>
<figure class="highlight dts"><table><tr><td class="code"><pre><span class="line"><span class="symbol">menu:</span></span><br><span class="line"><span class="symbol">  home:</span> / || home</span><br><span class="line">  <span class="meta">#about: /about/ || user</span></span><br><span class="line"><span class="symbol">  tags:</span> <span class="meta-keyword">/tags/</span> || tags</span><br><span class="line"><span class="symbol">  categories:</span> <span class="meta-keyword">/categories/</span> || th</span><br><span class="line"><span class="symbol">  archives:</span> <span class="meta-keyword">/archives/</span> || archive</span><br><span class="line">  <span class="meta">#schedule: /schedule/ || calendar</span></span><br><span class="line">  <span class="meta">#sitemap: /sitemap.xml || sitemap</span></span><br><span class="line">  <span class="meta">#commonweal: /404/ || heartbeat</span></span><br></pre></td></tr></table></figure>
<p>将其中的注释删除</p>
</li>
<li><p>部署</p>
<p> <code>hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</code></p>
</li>
</ol>
<h2 id="发布博文"><a href="#发布博文" class="headerlink" title="发布博文"></a>发布博文</h2><ol>
<li><p>git bash新建<br><code>hexo new &quot;文章名称&quot;</code><br>\Hexo\source_posts会出现相关的文章名称.md文件</p>
</li>
<li><p>修改.md文件</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">title:</span> <span class="string">title</span> <span class="comment">#文章標題</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">2016</span><span class="number">-06</span><span class="number">-01</span> <span class="number">23</span><span class="string">:47:44</span> <span class="comment">#文章生成時間</span></span><br><span class="line"><span class="attr">categories:</span> <span class="string">"Hexo教程"</span> <span class="comment">#文章分類目錄 可以省略</span></span><br><span class="line"><span class="attr">tags:</span> <span class="comment">#文章標籤 可以省略</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">标签1</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">标签2</span></span><br><span class="line"> <span class="attr">description:</span> <span class="comment">#你對本頁的描述 可以省略</span></span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>​    初始化只有title和data，添加categories和tags即可</p>
<ol start="3">
<li>撰写/保存/部署<br>其中不要忘记加入<code>&lt;!-- more --&gt;</code>进行摘要展示</li>
</ol>
<h2 id="常用的MD语法"><a href="#常用的MD语法" class="headerlink" title="常用的MD语法"></a>常用的MD语法</h2><p>​    MD用的少，word与latex比较熟悉，所以记录一下常用的</p>
<h4 id="标记与多重标记"><a href="#标记与多重标记" class="headerlink" title="标记与多重标记"></a>标记与多重标记</h4><p>使用&gt;与&gt;&gt;表示标记</p>
<blockquote>
<p>标记里再使用 </p>
<blockquote>
<p>标记</p>
</blockquote>
</blockquote>
<h4 id="多级标题"><a href="#多级标题" class="headerlink" title="多级标题"></a>多级标题</h4><p>使用1-6个#表示多级标题</p>
<h4 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h4><p>+-*表示无序列表</p>
<ul>
<li>我的微信公众号</li>
<li>我的微信公众号</li>
<li>我的微信公众号</li>
</ul>
<ul>
<li>我的尾巴</li>
</ul>
<p>数字加英文.表示有序列表</p>
<h4 id="分割线"><a href="#分割线" class="headerlink" title="分割线"></a>分割线</h4><p>分割线可以由* - _（星号，减号，底线）这3个符号的至少3个符号表示，注意至少要3个，且不需要连续，有空格也可以</p>
<hr>
<h4 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h4><p>链接的文字放在[]中，链接地址放在随后的（）中<br><a href="https://www.zhihu.com/people/liu-hao-33-54" target="_blank" rel="noopener">我的知乎</a></p>
<h4 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h4><p>与链接基本一致，加入！即可<br><img src="https://raw.githubusercontent.com/smshen/MarkdownPhotos/master/Res/test.jpg" alt="微信"></p>
<p>但是如果为本地图片地址，采取如下的方式：</p>
<h6 id="第一种方法"><a href="#第一种方法" class="headerlink" title="第一种方法"></a>第一种方法</h6><ul>
<li>在配置文件<strong>_config.yml</strong>里修改：<code>post_asset_folder: true</code></li>
<li>在Hexo安装目录下执行:<code>npm install hexo-asset-image --save</code>，这是下载安装一个可以上传本地图片的插件</li>
<li>等待一段时间之后，再运行<code>hexo n &quot;文章标题&quot;</code>来生成博文时，<code>/source/_post</code>文件夹中除了<code>文章标题.md</code>外，还有一个同名文件夹。</li>
<li>在新的博文中想引入图片时，可以先把图片复制到博文的同名文件夹，然后在<code>.md</code>中按照常规的方式饮用图片即可，如<code>![你想输入的替代文字](博文标题/图片名.jpg)</code>。<strong>注意，此处的图片路径必须使用相对路径</strong></li>
<li>执行<code>hexo g</code>,检查生成的页面中图片的src地址。此时生成页面中图片src地址应该与页面的相对路径一致（具体路径取决于页面路径格式设置）</li>
</ul>
<h6 id="第二种方法"><a href="#第二种方法" class="headerlink" title="第二种方法"></a>第二种方法</h6><p>以上方法可以解决本地图片上传和引用的问题，但是在每个文章下建立资源文件夹好处是分类清楚，缺点是图片复用不方便，也不符合网站设计的一般规范。</p>
<p>所以我们可以第二种方案：</p>
<ul>
<li>在本地source中建立img文件夹，将引用到的图片全部放在此文件夹中。这样操作也便于图片的复用。</li>
<li><strong>注意，采用这种方法时无需修改_config.yml,也无需安装hexo-asset-image</strong></li>
</ul>
<h4 id="强调"><a href="#强调" class="headerlink" title="强调"></a>强调</h4><p>*倾斜*<br>**加粗**<br>~~删除~~<br><em>倾斜</em><br><strong>加粗</strong><br><del>删除</del></p>
<h4 id="公式-转义"><a href="#公式-转义" class="headerlink" title="公式/转义"></a>公式/转义</h4><p>转移和latex等都差不多，用\即可</p>
<p>公式：</p>
<p>在用markdown写技术文档时，免不了会碰到数学公式。常用的Markdown编辑器都会集成Mathjax，用来渲染文档中的类Latex格式书写的数学公式。基于Hexo搭建的个人博客，默认情况下渲染数学公式却会出现各种各样的问题。</p>
<h6 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h6><p>Hexo 默认使用 hexo-renderer-marked 引擎渲染网页，该引擎会把一些特殊的 markdown 符号转换为相应的 html 标签，比如在 markdown 语法中，下划线<code>_</code>代表斜体，会被渲染引擎处理为``标签。</p>
<p>因为类 Latex 格式书写的数学公式下划线<code>_</code>表示下标，有特殊的含义，如果被强制转换为``标签，那么 MathJax 引擎在渲染数学公式的时候就会出错。</p>
<p>类似的语义冲突的符号还包括<code>*</code>, <code>{</code>, <code>}</code>, <code>\\</code>等。 </p>
<h6 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h6><p>更换 Hexo 的 markdown 渲染引擎，hexo-renderer-kramed 引擎是在默认的渲染引擎 hexo-renderer-marked 的基础上修改了一些 bug ，两者比较接近，也比较轻量级。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">npm <span class="keyword">uninstall</span> hexo-renderer-marked <span class="comment">--save</span></span><br><span class="line">npm <span class="keyword">install</span> hexo-renderer-kramed <span class="comment">--save1212</span></span><br></pre></td></tr></table></figure>

<p>执行上面的命令即可，先卸载原来的渲染引擎，再安装新的。<br>然后，跟换引擎后行间公式可以正确渲染了，但是这样还没有完全解决问题，行内公式的渲染还是有问题，因为 hexo-renderer-kramed 引擎也有语义冲突的问题。接下来到博客根目录下，找到node_modules\kramed\lib\rules\inline.js，把第11行的 escape 变量的值做相应的修改：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">//escape: /^\\([<span class="string">\\`*&#123;&#125;\[\</span>](<span class="link"></span>)#$+\-.!_&gt;])/,</span><br><span class="line">escape: /^\\([<span class="string">`*\[\</span>](<span class="link"></span>)#$+\-.!_&gt;])/,1212</span><br></pre></td></tr></table></figure>

<p>这一步是在原基础上取消了对,{,}的转义(escape)。<br>同时把第20行的em变量也要做相应的修改。</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">//em: /^\b<span class="emphasis">_((?:_</span><span class="emphasis">_|[\s\S])+?)_</span>\b|^\<span class="emphasis">*((?:\*</span>\<span class="emphasis">*|[\s\S])+?)\*</span>(?!\*)/,</span><br><span class="line">em: /^\<span class="emphasis">*((?:\*</span>\<span class="emphasis">*|[\s\S])+?)\*</span>(?!\*)/,1212</span><br></pre></td></tr></table></figure>

<p>重新启动hexo（先clean再generate）,问题完美解决。哦，如果不幸还没解决的话，看看是不是还需要在使用的主题中配置mathjax开关。</p>
<h6 id="在-Next-主题中开启-MathJax-开关"><a href="#在-Next-主题中开启-MathJax-开关" class="headerlink" title="在 Next 主题中开启 MathJax 开关"></a>在 Next 主题中开启 MathJax 开关</h6><p>如何使用了主题了，别忘了在主题（Theme）中开启 MathJax 开关，下面以 next 主题为例，介绍下如何打开 MathJax 开关。</p>
<p>进入到主题目录，找到 _config.yml 配置问题，把 math 默认的 false 修改为true，具体如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Math Equations Render Support</span></span><br><span class="line"><span class="attr">math:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Default(true) will load mathjax/katex script on demand</span></span><br><span class="line">  <span class="comment"># That is it only render those page who has 'mathjax: true' in Front Matter.</span></span><br><span class="line">  <span class="comment"># If you set it to false, it will load mathjax/katex srcipt EVERY PAGE.</span></span><br><span class="line">  <span class="attr">per_page:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">engine:</span> <span class="string">mathjax</span></span><br><span class="line">  <span class="comment">#engine: katex12345678910111234567891011</span></span><br></pre></td></tr></table></figure>

<p>还需要在文章的Front-matter里打开mathjax开关，如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">index.html</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">2018</span><span class="number">-07</span><span class="number">-05</span> <span class="number">12</span><span class="string">:01:30</span></span><br><span class="line"><span class="attr">tags:</span></span><br><span class="line"><span class="attr">mathjax:</span> <span class="literal">true</span></span><br><span class="line"><span class="string">--123456123456</span></span><br></pre></td></tr></table></figure>

<p>之所以要在文章头里设置开关，是因为考虑只有在用到公式的页面才加载 Mathjax，这样不需要渲染数学公式的页面的访问速度就不会受到影响了。</p>
<h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><p>如果代码量比较少，只有单行的话，可以用单反引号包起来，如下：<br><code>asd</code><br>如果多行就用</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> main&#123;</span><br><span class="line">	<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; temp;</span><br><span class="line">	<span class="comment">//...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Hexo操作</category>
      </categories>
      <tags>
        <tag>-hexo -md</tag>
      </tags>
  </entry>
  <entry>
    <title>关于博客</title>
    <url>/2020/03/08/%E5%85%B3%E4%BA%8E%E8%BF%99%E4%B8%AA%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<p>为了规则、规律地进行记录与分享,主要分为以下4个方面</p>
<h2 id="c-刷题笔记"><a href="#c-刷题笔记" class="headerlink" title="c++/刷题笔记"></a>c++/刷题笔记</h2><h2 id="时事吐槽"><a href="#时事吐槽" class="headerlink" title="时事吐槽"></a>时事吐槽</h2><h2 id="学习-实习"><a href="#学习-实习" class="headerlink" title="学习/实习"></a>学习/实习</h2><h2 id="comment-share"><a href="#comment-share" class="headerlink" title="comment/share"></a>comment/share</h2>]]></content>
  </entry>
</search>
